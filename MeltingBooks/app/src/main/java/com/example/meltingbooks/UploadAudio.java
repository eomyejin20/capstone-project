package com.example.meltingbooks;

import android.Manifest;
import android.content.Context;
import android.content.Intent;
import android.content.pm.PackageManager;
import android.net.Uri;
import android.os.Bundle;
import android.os.Build;
import android.text.Editable;
import android.text.TextWatcher;
import android.util.Log;
import android.view.View;
import android.view.inputmethod.InputMethodManager;
import android.widget.Button;
import android.widget.EditText;
import android.widget.ImageButton;
import android.widget.ImageView;
import android.widget.LinearLayout;
import android.widget.Toast;

import android.speech.SpeechRecognizer;
import android.speech.RecognizerIntent;
import android.speech.RecognitionListener;

import java.io.IOException;
import java.util.ArrayList;
import java.util.Locale;

import androidx.activity.result.ActivityResultLauncher;
import androidx.activity.result.contract.ActivityResultContracts;
import androidx.annotation.NonNull;
import androidx.appcompat.app.AppCompatActivity;
import androidx.core.app.ActivityCompat;
import androidx.core.content.ContextCompat;

import com.example.meltingbooks.R;
import com.google.firebase.storage.FirebaseStorage;
import com.google.firebase.storage.StorageReference;

//ChatGPT API
import okhttp3.*;
import okhttp3.Call;
import okhttp3.Callback;
import okhttp3.MediaType;
import okhttp3.OkHttpClient;
import okhttp3.Request;
import okhttp3.RequestBody;
import okhttp3.Response;
import org.json.JSONArray;
import org.json.JSONException;
import org.json.JSONObject;

import com.example.meltingbooks.BuildConfig;

public class UploadAudio extends AppCompatActivity {
    private String apiKey;  // apiKeyëŠ” ì´ì œ onCreate()ì—ì„œ ì´ˆê¸°í™”
    private Request request;  // requestëŠ” callAPI() ë©”ì„œë“œ ë‚´ì—ì„œ ìƒì„±
    private static final int REQUEST_PERMISSION_CODE = 1001;
    private ImageButton btnRecord, btnAddFile, btnLike, btnHashtag, btnUpload;
    private EditText etInput;
    private Button btnSummarize;
    private LinearLayout middleLayout, bottomLayout;
    private boolean isKeyboardVisible = false;
    private ImageView imageView;
    private StorageReference storageReference;

    private ActivityResultLauncher<Intent> imagePickerLauncher;

    private SpeechRecognizer speechRecognizer;
    final int PERMISSION = 1;
    private Intent intent;
    private Intent speechRecognizerIntent;

    private ImageView micImageView, summarizingImageView;

    // ChatGPT API client setup
    private OkHttpClient client;


    @Override
    protected void onCreate(Bundle savedInstanceState) {
        super.onCreate(savedInstanceState);
        setContentView(R.layout.activity_write);

        String apiKey = BuildConfig.OPENAI_API_KEY;

        ///ì•ˆë“œë¡œì´ë“œ 6.0ë²„ì „ ì´ìƒì¸ì§€ ì²´í¬í•´ì„œ í¼ë¯¸ì…˜
        if(Build.VERSION.SDK_INT >= 23){
            ActivityCompat.requestPermissions(this, new String[] {Manifest.permission.INTERNET,
                    Manifest.permission.RECORD_AUDIO},PERMISSION);
        }

        storageReference = FirebaseStorage.getInstance().getReference("audio");

        btnUpload = findViewById(R.id.btnUpload);
        btnAddFile = findViewById(R.id.btnAddFile);
        btnLike = findViewById(R.id.btnLike);
        btnHashtag = findViewById(R.id.btnHashtag);
        imageView = findViewById(R.id.imageView);
        etInput = findViewById(R.id.etInput);
        middleLayout = findViewById(R.id.middleLayout);
        bottomLayout = findViewById(R.id.bottomLayout);
        btnRecord = findViewById(R.id.btnRecord);
        btnSummarize = findViewById(R.id.btnSummarize);

        micImageView = findViewById(R.id.micON);
        summarizingImageView = findViewById(R.id.summarizing);

        // Initialize OkHttpClient for ChatGPT API
        client = new OkHttpClient();

        // ìŒì„± ì¸ì‹ ê¶Œí•œ í™•ì¸
        checkPermissions();

        // editText ê¸°ëŠ¥
        etInput.setOnClickListener(v -> {
            if (isKeyboardVisible) {
                // í‚¤ë³´ë“œê°€ ë³´ì´ë©´ ìˆ¨ê¹€
                hideKeyboard();
            } else {
                // í‚¤ë³´ë“œê°€ ìˆ¨ê²¨ì ¸ ìˆìœ¼ë©´ ë³´ì„
                etInput.requestFocus();
                InputMethodManager imm = (InputMethodManager) getSystemService(Context.INPUT_METHOD_SERVICE);
                imm.showSoftInput(etInput, InputMethodManager.SHOW_IMPLICIT);
            }
            isKeyboardVisible = !isKeyboardVisible; // í‚¤ë³´ë“œ ìƒíƒœ ë°˜ì „
        });

        // ì²¨ë¶€ íŒŒì¼ ì¶”ê°€
        imagePickerLauncher = registerForActivityResult(
                new ActivityResultContracts.StartActivityForResult(),
                result -> {
                    if (result.getResultCode() == RESULT_OK && result.getData() != null) {
                        Uri imageUri = result.getData().getData();
                        imageView.setImageURI(imageUri);
                    }
                });

        btnAddFile.setOnClickListener(v -> {
            Intent intent = new Intent();
            intent.setType("image/*");
            intent.setAction(Intent.ACTION_GET_CONTENT);
            imagePickerLauncher.launch(intent);
        });

        checkPermissions();

        btnLike.setOnClickListener(v -> {
            // ì¢‹ì•„ìš” ê¸°ëŠ¥ êµ¬í˜„
        });

        btnHashtag.setOnClickListener(v -> {
            // í•´ì‹œíƒœê·¸ ê¸°ëŠ¥ êµ¬í˜„
        });

        // EditTextì— ì…ë ¥ ê°ì§€í•˜ëŠ” TextWatcher ì¶”ê°€
        etInput.addTextChangedListener(new TextWatcher() {
            @Override
            public void beforeTextChanged(CharSequence s, int start, int count, int after) {}

            @Override
            public void onTextChanged(CharSequence s, int start, int before, int count) {
                // ì…ë ¥ëœ í…ìŠ¤íŠ¸ ê¸¸ì´ê°€ 5ì ì´ìƒì´ë©´ ë²„íŠ¼ í™œì„±í™”
                if (s.length() >= 5) {
                    btnSummarize.setVisibility(View.VISIBLE);  // ì…ë ¥ 5ì ì´ìƒ â†’ ë²„íŠ¼ ë³´ì´ê¸°
                } else {
                    btnSummarize.setVisibility(View.GONE);  // 5ì ë¯¸ë§Œ â†’ ë²„íŠ¼ ìˆ¨ê¸°ê¸°
                }
            }

            @Override
            public void afterTextChanged(Editable s) {}
        });

        // ìš”ì•½í•˜ê¸° ë²„íŠ¼ í´ë¦­ ë¦¬ìŠ¤ë„ˆ
        btnSummarize.setOnClickListener(v -> {
            //ìš”ì•½í•˜ê¸° ë²„íŠ¼ ìˆ¨ê¸°ê¸°
            btnSummarize.setVisibility(View.GONE);
            // ìš”ì•½ ì¤‘ ì´ë¯¸ì§€ë¥¼ ë³´ì´ê²Œ
            summarizingImageView.setVisibility(View.VISIBLE);

            // í…ìŠ¤íŠ¸ë¥¼ ìš”ì•½í•˜ëŠ” ë¡œì§
            String inputText = etInput.getText().toString();
            callAPI(inputText);  // ChatGPT API í˜¸ì¶œ
        });

        /// RecognizerIntent ìƒì„±
        intent = new Intent(RecognizerIntent.ACTION_RECOGNIZE_SPEECH);
        //intent.putExtra(RecognizerIntent.EXTRA_LANGUAGE_MODEL, RecognizerIntent.LANGUAGE_MODEL_FREE_FORM);
        intent.putExtra(RecognizerIntent.EXTRA_CALLING_PACKAGE,getPackageName()); // ì—¬ë¶„ì˜ í‚¤
        intent.putExtra(RecognizerIntent.EXTRA_LANGUAGE, Locale.getDefault());
        intent.putExtra(RecognizerIntent.EXTRA_LANGUAGE,"ko-KR"); // ì–¸ì–´ ì„¤ì •
        //intent.putExtra(RecognizerIntent.EXTRA_LANGUAGE, Locale.getDefault().toString()); // ê¸°ê¸°ì˜ ê¸°ë³¸ ì–¸ì–´ë¡œ ì„¤ì •


        // btnRecord í´ë¦­ ë¦¬ìŠ¤ë„ˆì—ì„œ micON ì´ë¯¸ì§€ ë·°ë¥¼ í‘œì‹œ
        btnRecord.setOnClickListener(new View.OnClickListener() {
            @Override
            public void onClick(View v) {
                btnSummarize.setVisibility(View.GONE);
                initSpeechRecognizer();
                speechRecognizer = SpeechRecognizer.createSpeechRecognizer(UploadAudio.this); // ìƒˆ SpeechRecognizer ë¥¼ ë§Œë“œëŠ” íŒ©í† ë¦¬ ë©”ì„œë“œ
                speechRecognizer.setRecognitionListener(listener); // ë¦¬ìŠ¤ë„ˆ ì„¤ì •
                // micON ë·°ë¥¼ ì°¾ê³  visibilityë¥¼ VISIBLEë¡œ ë³€ê²½
                if (micImageView != null) {
                    micImageView.setVisibility(View.VISIBLE);  // micON ì´ë¯¸ì§€ ë·°ë¥¼ ë³´ì´ë„ë¡ ì„¤ì •
                }
                etInput.setHint("");  // hintë¥¼ ë¹ˆ ë¬¸ìì—´ë¡œ ì„¤ì •
                speechRecognizer.startListening(intent); // ë“£ê¸° ì‹œì‘
            }
        });

        checkPermissions();

    }

    private RecognitionListener listener = new RecognitionListener() {
        @Override
        public void onReadyForSpeech(Bundle params) {
            showSpeechRecognitionUI();
            // ë§í•˜ê¸° ì‹œì‘í•  ì¤€ë¹„ê°€ë˜ë©´ í˜¸ì¶œ
        }

        @Override
        public void onBeginningOfSpeech() {
            // ë§í•˜ê¸° ì‹œì‘í–ˆì„ ë•Œ í˜¸ì¶œ
        }

        @Override
        public void onRmsChanged(float rmsdB) {
            // ì…ë ¥ë°›ëŠ” ì†Œë¦¬ì˜ í¬ê¸°ë¥¼ ì•Œë ¤ì¤Œ
        }

        @Override
        public void onBufferReceived(byte[] buffer) {
            // ë§ì„ ì‹œì‘í•˜ê³  ì¸ì‹ì´ ëœ ë‹¨ì–´ë¥¼ bufferì— ë‹´ìŒ
        }

        @Override
        public void onEndOfSpeech() {
            // ë§í•˜ê¸°ë¥¼ ì¤‘ì§€í•˜ë©´ í˜¸ì¶œ
        }

        @Override
        public void onError(int error) {
            Log.e("SpeechRecognizer", "ì˜¤ë¥˜ ì½”ë“œ: " + error); // ì˜¤ë¥˜ ì½”ë“œ í™•ì¸
            String message;

            switch (error) {
                case SpeechRecognizer.ERROR_AUDIO:
                    message = "ì˜¤ë””ì˜¤ ë…¹ìŒ ì˜¤ë¥˜";
                    break;
                case SpeechRecognizer.ERROR_CLIENT:
                    message = "í´ë¼ì´ì–¸íŠ¸ ì˜¤ë¥˜";
                    break;
                case SpeechRecognizer.ERROR_INSUFFICIENT_PERMISSIONS:
                    message = "ê¶Œí•œ ì—†ìŒ";
                    break;
                case SpeechRecognizer.ERROR_NETWORK:
                    message = "ë„¤íŠ¸ì›Œí¬ ì˜¤ë¥˜";
                    break;
                case SpeechRecognizer.ERROR_NETWORK_TIMEOUT:
                    message = "ë„¤íŠ¸ì›Œí¬ íƒ€ì„ì•„ì›ƒ";
                    break;
                case SpeechRecognizer.ERROR_NO_MATCH:
                    message = "ìŒì„±ì„ ì¸ì‹í•˜ì§€ ëª»í–ˆìŠµë‹ˆë‹¤. ë‹¤ì‹œ ì‹œë„í•´ ì£¼ì„¸ìš”.";
                    break;
                case SpeechRecognizer.ERROR_RECOGNIZER_BUSY:
                    message = "ìŒì„± ì¸ì‹ê¸°ê°€ ì‚¬ìš© ì¤‘ì…ë‹ˆë‹¤. ì ì‹œ í›„ ë‹¤ì‹œ ì‹œë„í•´ ì£¼ì„¸ìš”.";
                    break;
                case SpeechRecognizer.ERROR_SERVER:
                    message = "ì„œë²„ ì˜¤ë¥˜ ë°œìƒ";
                    break;
                case SpeechRecognizer.ERROR_SPEECH_TIMEOUT:
                    message = "ì…ë ¥ ì‹œê°„ì´ ì´ˆê³¼ë˜ì—ˆìŠµë‹ˆë‹¤. ë‹¤ì‹œ ì‹œë„í•´ ì£¼ì„¸ìš”.";
                    break;
                default:
                    message = "ì•Œ ìˆ˜ ì—†ëŠ” ì˜¤ë¥˜ ë°œìƒ (ì½”ë“œ: " + error + ")";
                    break;
            }

            Log.e("SpeechRecognizer", "ì—ëŸ¬ ë©”ì‹œì§€: " + message); // ì—ëŸ¬ ë©”ì‹œì§€ ì¶œë ¥ í™•ì¸
            Toast.makeText(getApplicationContext(), "ì—ëŸ¬ ë°œìƒ : " + message, Toast.LENGTH_SHORT).show();
            hideSpeechRecognitionUI();
            etInput.setHint("ë…ì„œ í›„ ëŠë‚Œì„ ê³µìœ í•´ ë³´ì„¸ìš”!");  // ê¸°ë³¸ hintë¡œ ì„¤ì •
        }

        @Override
        public void onResults(Bundle results) {
            ArrayList<String> matches =
                    results.getStringArrayList(SpeechRecognizer.RESULTS_RECOGNITION);
            if (matches != null && !matches.isEmpty()) {
                etInput.setText(matches.get(0)); // ì¸ì‹ëœ ì²« ë²ˆì§¸ í…ìŠ¤íŠ¸ë¥¼ etInputì— ì„¤ì •
                etInput.setSelection(etInput.getText().length()); // ğŸ”¥ ì»¤ì„œë¥¼ ë§¨ ë’¤ë¡œ ì´ë™
                // ìŒì„± ì¸ì‹ì´ ì™„ë£Œë˜ë©´ ìš”ì•½í•˜ê¸° ë²„íŠ¼ì„ ë³´ì´ê²Œ ì„¤ì •
                btnSummarize.setVisibility(View.VISIBLE);
            }
            hideSpeechRecognitionUI();  // ìŒì„± ì¸ì‹ í›„ UI ìˆ¨ê¹€
        }

        @Override
        public void onPartialResults(Bundle partialResults) {
            // ë¶€ë¶„ ì¸ì‹ ê²°ê³¼ë¥¼ ì‚¬ìš©í•  ìˆ˜ ìˆì„ ë•Œ í˜¸ì¶œ
        }

        @Override
        public void onEvent(int eventType, Bundle params) {
            // í–¥í›„ ì´ë²¤íŠ¸ë¥¼ ì¶”ê°€í•˜ê¸° ìœ„í•´ ì˜ˆì•½
        }
    };

    //ìŒì„±ì¸ì‹ ì´ˆê¸°í™” í•œ ë²ˆë§Œ
    private void initSpeechRecognizer() {
        if (speechRecognizer != null) {
            speechRecognizer.destroy();
            speechRecognizer = null;
        }

        speechRecognizer = SpeechRecognizer.createSpeechRecognizer(this);
        speechRecognizer.setRecognitionListener(listener);
    }

    private void checkPermissions() {
        if (ContextCompat.checkSelfPermission(this, Manifest.permission.RECORD_AUDIO) != PackageManager.PERMISSION_GRANTED) {
            ActivityCompat.requestPermissions(this, new String[]{Manifest.permission.RECORD_AUDIO}, REQUEST_PERMISSION_CODE);
        }
    }

    private void hideKeyboard() {
        InputMethodManager imm = (InputMethodManager) getSystemService(Context.INPUT_METHOD_SERVICE);
        imm.hideSoftInputFromWindow(etInput.getWindowToken(), 0);
    }

    @Override
    public void onRequestPermissionsResult(int requestCode, @NonNull String[] permissions, @NonNull int[] grantResults) {
        super.onRequestPermissionsResult(requestCode, permissions, grantResults);

        if (requestCode == REQUEST_PERMISSION_CODE) {
            if (grantResults.length > 0 && grantResults[0] == PackageManager.PERMISSION_GRANTED) {
                Toast.makeText(this, "ê¶Œí•œ í—ˆìš© ì™„ë£Œ", Toast.LENGTH_SHORT).show();
            } else {
                Toast.makeText(this, "ê¶Œí•œì„ í—ˆìš©í•´ì•¼ ìŒì„± ì¸ì‹ì´ ê°€ëŠ¥í•©ë‹ˆë‹¤.", Toast.LENGTH_SHORT).show();
            }
        }
    }

    private void showSpeechRecognitionUI() {
        // ìŒì„± ì¸ì‹ ì¤‘ ì´ë¯¸ì§€ ë³´ì´ê¸°
        if (micImageView != null) {
            micImageView.setVisibility(View.VISIBLE);  // micON ì´ë¯¸ì§€ë¥¼ ë³´ì´ë„ë¡ ì„¤ì •
        }
    }

    // ìŒì„± ì¸ì‹ ì¢…ë£Œ í›„ UI ìˆ¨ê¹€
    private void hideSpeechRecognitionUI() {
        // micONì„ ì°¾ì•„ì„œ ìˆ¨ê¹€
        if (micImageView != null) {
            micImageView.setVisibility(View.GONE);  // micON ì´ë¯¸ì§€ ë·°ë¥¼ ìˆ¨ê¹€
        }
    }

    // ChatGPT API í˜¸ì¶œ
    private void callAPI(String question) {
        // ìš”ì•½ ì¤‘ ì´ë¯¸ì§€ë¥¼ ë³´ì´ê²Œ
        summarizingImageView.setVisibility(View.VISIBLE);

        JSONObject object = new JSONObject();
        try {
            object.put("model", "gpt-3.5-turbo");
            JSONArray messagesArray = new JSONArray();

            // ì‹œìŠ¤í…œ ì—­í•  ì¶”ê°€
            JSONObject systemMessage = new JSONObject();
            systemMessage.put("role", "system");
            systemMessage.put("content", "You are a helpful assistant that summarizes text.");
            messagesArray.put(systemMessage);

            // ì‚¬ìš©ì ì…ë ¥ ì¶”ê°€
            JSONObject messageObj = new JSONObject();
            messageObj.put("role", "user");
            messageObj.put("content", "ë‹¤ìŒ ë‚´ìš©ì„ ì‚¬ìš©ìì˜ ê°ìƒì„ ë°˜ì˜í•˜ì—¬ ìš”ì•½í•´ì¤˜:\\n" + question);  // ëª…í™•í•œ ìš”ì²­ ì¶”ê°€
            messagesArray.put(messageObj);
            object.put("messages", messagesArray);
            object.put("temperature", 0.7); // ë‹¤ì–‘ì„±ì„ ì¡°ì ˆí•˜ëŠ” ì˜µì…˜
        } catch (JSONException e) {
            e.printStackTrace();
        }

        RequestBody body = RequestBody.create(object.toString(), MediaType.get("application/json; charset=utf-8"));
        request = new Request.Builder()
                .url("https://api.openai.com/v1/chat/completions")
                .header("Authorization", "Bearer " + apiKey)  // apiKeyë¥¼ ì‚¬ìš©
                .post(body)
                .build();

        client.newCall(request).enqueue(new Callback() {
            @Override
            public void onFailure(@NonNull Call call, @NonNull IOException e) {
                // ìš”ì²­ ì‹¤íŒ¨ ì²˜ë¦¬
                runOnUiThread(() -> {
                    summarizingImageView.setVisibility(View.GONE);  // ìš”ì•½ ì¤‘ ì´ë¯¸ì§€ ìˆ¨ê¸°ê¸°
                    Toast.makeText(UploadAudio.this, "ìš”ì•½ ì‹¤íŒ¨", Toast.LENGTH_SHORT).show();
                });
            }

            @Override
            public void onResponse(@NonNull Call call, @NonNull Response response) throws IOException {
                String responseBody = response.body().string();
                Log.d("API_RESPONSE", responseBody);  // ì‘ë‹µ ë¡œê¹…


                if (response.isSuccessful()) {
                    try {
                        JSONObject jsonResponse = new JSONObject(responseBody);
                        JSONArray choices = jsonResponse.getJSONArray("choices");
                        String summarizedText = choices.getJSONObject(0).getJSONObject("message").getString("content");

                        runOnUiThread(() -> {
                            etInput.setText(summarizedText);
                            summarizingImageView.setVisibility(View.GONE);
                            btnSummarize.setVisibility(View.VISIBLE);
                        });
                    } catch (JSONException e) {
                        e.printStackTrace();
                    }
                } else {
                    runOnUiThread(() -> {
                        summarizingImageView.setVisibility(View.GONE);
                        Toast.makeText(UploadAudio.this, "API í˜¸ì¶œ ì˜¤ë¥˜: " + responseBody, Toast.LENGTH_SHORT).show();
                    });
                }
            }
        });
    }
}
